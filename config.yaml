# Original GliomaGen Parameters

dataset:
  input_root: "BraTS2024-GLI/training"                      # Path to the raw training data
  output_root: "BraTS2024-GLI/3_gli_head_mask_normalized_multimodal"  # Where processed files are saved
  modalities: ["t1n", "t1c", "t2w", "t2f"]    # List of modalities to process
  mask_labels: [0, 1, 2, 3, 4, 5]              # The mask labels after shifting
  original_data_size: [192, 192, 144]          # Original data dimensions
  train_samples: 1300                         # (Optional) Number of training subjects
  val_samples: 50                             # (Optional) Number of validation subjects

preprocessing:
  target_shape: [192, 192, 144]               # Size to which images/masks are resized (each dimension should be a multiple of 16)
  label_shift: 1                              # Value to shift mask labels
  new_label: 1                                # Label for the head region
  original_label_range: [0, 4]                # Original range of labeled masks

model:
  input_size: [192, 192, 144]                 # Model input dimensions
  num_channels: 64                            # Base number of channels for the model
  num_res_blocks: 2                           # Number of residual blocks
  num_class_labels: 6                         # Total segmentation classes (including background)
  out_channels: 4                             # Number of output channels (e.g. one per modality)
  with_condition: true                        # Whether to condition the model on additional data
  resume_weight: ""                           # Path to pretrained weights (if any)
  resume_step_offset: 0                       # Step offset for resuming training

training:
  train_lr: 1e-5                              # Learning rate
  batch_size: 1                               # Batch size
  epochs: 245000                              # Total training iterations/epochs
  timesteps: 1000                             # Number of diffusion timesteps
  save_and_sample_every: 2500                 # Frequency for saving/sampling
  num_workers: 16                             # Number of DataLoader workers
  freeze_encoder_at_step: 170000              # Step at which to freeze encoder layers
  early_stopping_patience: 20000              # Steps with no improvement before stopping training
  early_stopping_delta: 0.0                   # Minimum change in monitored metric to qualify as improvement
  val_interval_steps: 5000                    # Validate every this many training steps
  num_val_batches: 1                         # Number of validation batches per validation step

lr_schedule:
  milestones: [65000, 75000, 85000, 100000]
  factors: [1.0, 0.75, 0.5, 0.25, 0.1]